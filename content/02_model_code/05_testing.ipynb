{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1a21aa7",
   "metadata": {},
   "source": [
    "# Model testing\n",
    "\n",
    "This notebook provides a set of tests to run against `treat_sim`.  These tests are either pass or fail and no interpretation is needed. A summary of test results is provided at the end of the notebook.\n",
    "\n",
    "> This notebook is a work in progress and more tests will be added in due course.\n",
    "\n",
    "We have broken the testing of `treat_sim` into the following sections\n",
    "\n",
    "* **Run tests:**.  These provide tests of the overall setup of the model including the ability to do repeatable single and multiple replications works as expected.\n",
    "* **Extreme value tests:** The model is configured with extreme values for its parameters. For example, limiting arrivals, blocking routes, infinite capacity.\n",
    "* **Deterministic runs:** Test if the model output behaves as expected if activites are converted to a deterministic value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d9529",
   "metadata": {},
   "source": [
    "## 1. Model Code Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09687392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from treat_sim.model import (\n",
    "    Scenario, \n",
    "    TreatmentCentreModel,\n",
    "    single_run, \n",
    "    multiple_replications\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e8ce8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## these tests are applied to treat_sim version =\n",
    "import treat_sim\n",
    "treat_sim.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44a3be2",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdf6c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import pytest\n",
    "import ipytest\n",
    "\n",
    "# types library is used to overwrite methods from treat_sim\n",
    "import types\n",
    "\n",
    "# sim_tools fixed dist is used for deterministic runs\n",
    "from sim_tools.distributions import FixedDistribution\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0996fe4d",
   "metadata": {},
   "source": [
    "## 3. Tests\n",
    "\n",
    "### 3.1 Model run test\n",
    "\n",
    "Here we test that various modes of running the model work correctly.  These include\n",
    "\n",
    "* single run mode\n",
    "* multiple replications mode\n",
    "* repeatable results using random number sets.\n",
    "* results collection period\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d22b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_run_results_length_and_type():\n",
    "    '''\n",
    "    Test a single_run of the model.\n",
    "    \n",
    "    The single_run function should return a pandas.DataFrame\n",
    "    containing 16 columns and a single row.\n",
    "    \n",
    "     0   00_arrivals                    \n",
    "     1   01a_triage_wait                 \n",
    "     2   01b_triage_util               \n",
    "     3   02a_registration_wait         \n",
    "     4   02b_registration_util        \n",
    "     5   03a_examination_wait          \n",
    "     6   03b_examination_util          \n",
    "     7   04a_treatment_wait(non_trauma)  \n",
    "     8   04b_treatment_util(non_trauma)  \n",
    "     9   05_total_time(non-trauma)       \n",
    "     10  06a_trauma_wait               \n",
    "     11  06b_trauma_util                 \n",
    "     12  07a_treatment_wait(trauma)      \n",
    "     13  07b_treatment_util(trauma)      \n",
    "     14  08_total_time(trauma)           \n",
    "     15  09_throughput                   \n",
    "\n",
    "    Expected result: \n",
    "    ---------------\n",
    "        len(run_results) == 16 and isinstance(run_results, pd.Dataframe)\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    bool: does the model pass the test.\n",
    "    '''\n",
    "    EXPECTED_LENGTH = 16\n",
    "\n",
    "    # a default experiment\n",
    "    default_experiment_params = Scenario()\n",
    "\n",
    "    # run the model in single run model\n",
    "    run_results = single_run(default_experiment_params, random_no_set=41)\n",
    "\n",
    "    # test\n",
    "    assert len(run_results.T) == EXPECTED_LENGTH and isinstance(run_results, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a428e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('n_reps', [\n",
    "                          (1),\n",
    "                          (2),\n",
    "                          (10),\n",
    "                          (23)\n",
    "])\n",
    "def test_multiple_replications_results_length_and_type(n_reps):\n",
    "    '''\n",
    "    Test running the model in multiple replications mode\n",
    "    \n",
    "    The multiple function should return a pandas.DataFrame\n",
    "    containing 16 columns and n_reps rows. Its shape is (n_reps, 16)\n",
    "    \n",
    "     0   00_arrivals                    \n",
    "     1   01a_triage_wait                 \n",
    "     2   01b_triage_util               \n",
    "     3   02a_registration_wait         \n",
    "     4   02b_registration_util        \n",
    "     5   03a_examination_wait          \n",
    "     6   03b_examination_util          \n",
    "     7   04a_treatment_wait(non_trauma)  \n",
    "     8   04b_treatment_util(non_trauma)  \n",
    "     9   05_total_time(non-trauma)       \n",
    "     10  06a_trauma_wait               \n",
    "     11  06b_trauma_util                 \n",
    "     12  07a_treatment_wait(trauma)      \n",
    "     13  07b_treatment_util(trauma)      \n",
    "     14  08_total_time(trauma)           \n",
    "     15  09_throughput                   \n",
    "\n",
    "    Expected result: \n",
    "    ---------------\n",
    "        rep_results.shape == (n_reps, 16) and isinstance(rep_results, pd.DataFrame)\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    bool: does the model pass the test.\n",
    "    '''\n",
    "    EXPECTED_N_COLUMNS = 16\n",
    "    EXPECTED_SHAPE = (n_reps, EXPECTED_N_COLUMNS)\n",
    "\n",
    "    # a default experiment\n",
    "    default_experiment_params = Scenario()\n",
    "\n",
    "    # run the model in multiple replications mode\n",
    "    rep_results = multiple_replications(default_experiment_params, n_reps=n_reps)\n",
    "\n",
    "    # test\n",
    "    assert rep_results.shape == EXPECTED_SHAPE and isinstance(rep_results, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aecfad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('random_number_set', [\n",
    "                          (0),\n",
    "                          (1),\n",
    "                          (2),\n",
    "                          (101),\n",
    "                          (42),\n",
    "])\n",
    "def test_random_number_set(random_number_set):\n",
    "    '''\n",
    "    Test the model produces repeatable results\n",
    "    given the same set set of random seeds.\n",
    "    \n",
    "    Expected result: \n",
    "    ---------------\n",
    "        difference between data frames is 0.0\n",
    "    '''\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(2):\n",
    "        \n",
    "        exp = Scenario()\n",
    "\n",
    "        # run the model in single run model\n",
    "        run_results = single_run(exp, random_no_set=random_number_set)\n",
    "    \n",
    "        results.append(run_results)\n",
    "        \n",
    "    # test\n",
    "    assert (results[0] - results[1]).sum().sum() == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bf9fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('rc_period', [\n",
    "                          (10.0),\n",
    "                          (1_000.0),\n",
    "                          (25.0),\n",
    "                          (500.0),\n",
    "                          (143.0),\n",
    "])\n",
    "def test_run_length_control(rc_period):\n",
    "    scenario = Scenario()\n",
    "    \n",
    "    # set random number set - this controls sampling for the run.\n",
    "    scenario.set_random_no_set(42)\n",
    "\n",
    "    # create an instance of the model\n",
    "    model = TreatmentCentreModel(scenario)\n",
    "\n",
    "    # run the model\n",
    "    model.run(results_collection_period=rc_period)\n",
    "        \n",
    "    # run results\n",
    "    assert model.env.now == rc_period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a798999",
   "metadata": {},
   "source": [
    "### 3.2. Extreme value tests\n",
    "\n",
    "Here we manipulate the input parameters of the model to test that it behaves as expected. We run the following tests\n",
    "\n",
    "* All arrivals are trauma\n",
    "* All arrivals are non-trauma\n",
    "* Infinite capacity for activities\n",
    "* All non-trauma patients require treatment\n",
    "* All non-trauma patients do not require treatment\n",
    "\n",
    "> To do: *Zero arrivals of both types\"\" -> Requires modification of `Scenario` \n",
    "\n",
    "> To investigate: blocked queues.  Simpy requires you to set resource count >=1; so cannot be simply blocked.  One way around this an arrival at time 0 and set activity time of the key activity to $M$ wa very large number. This means that the 1st patient arrives before the \"real\" arrival process begins, takes the 1 resource available and blocks the queue.  Do we actually need to do this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fcd516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87772dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54d64098",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: we are ignoring mean of empty array warnings from numpy using filterwarnings\n",
    "### We will handle this in a future release of treat_sim.\n",
    "\n",
    "@pytest.mark.filterwarnings(\"ignore\")\n",
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555), \n",
    "])\n",
    "def test_all_trauma(random_no_set):\n",
    "    '''\n",
    "    Force all patients to use trauma pathway\n",
    "    \n",
    "    i.e. Set prob_trauma = 1.0\n",
    "    \n",
    "    Expected result:\n",
    "    -------\n",
    "    No patients use the non-trauma pathway this means that a number of KPIs\n",
    "    are NaN (not a number). These include:\n",
    "    '02a_registration_wait'\n",
    "    '05_total_time(non-trauma)'\n",
    "    \n",
    "    Trauma pathway KPIs are valid numbers. We test total time in \n",
    "    system: '08_total_time(trauma)'\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(prob_trauma=1.0)\n",
    "\n",
    "    # run the model in single run model\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "        \n",
    "    # run results\n",
    "    assert (pd.isna(run_results['05_total_time(non-trauma)'].iloc[0]) \n",
    "            and pd.isna(run_results['02a_registration_wait'].iloc[0]) \n",
    "            and not pd.isna(run_results['08_total_time(trauma)'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cddddffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: we are ignoring mean of empty array warnings from numpy using filterwarnings\n",
    "### We will handle this in a future release of treat_sim.\n",
    "\n",
    "@pytest.mark.filterwarnings(\"ignore\")\n",
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555), \n",
    "])\n",
    "def test_all_nontrauma(random_no_set):\n",
    "    '''\n",
    "    Force all patients to use the non-trauma pathway\n",
    "    \n",
    "    i.e. Set prob_trauma = 0.0\n",
    "    \n",
    "    Expected result:\n",
    "    -------\n",
    "    No patients use the trauma pathway this means that a number of KPIs\n",
    "    if NaN (Not a Number) as no patient use the activities.\n",
    "    \n",
    "    '06a_trauma_wait'\n",
    "    '07a_treatment_wait(trauma)'\n",
    "    '08_total_time(trauma)'\n",
    "    \n",
    "    Non-trauma pathway KPIs are valid numbers. We test\n",
    "    '02a_registration_wait'\n",
    "    '05_total_time(non-trauma)'\n",
    "    '''\n",
    "    \n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(prob_trauma=0.0)\n",
    "\n",
    "    # run the model in single run model\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "        \n",
    "    # run results\n",
    "    assert (pd.isna(run_results['06a_trauma_wait'].iloc[0]) \n",
    "            and pd.isna(run_results['07a_treatment_wait(trauma)'].iloc[0]) \n",
    "            and pd.isna(run_results['08_total_time(trauma)'].iloc[0]) \n",
    "            and not pd.isna(run_results['02a_registration_wait'].iloc[0])\n",
    "            and not pd.isna(run_results['05_total_time(non-trauma)'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbca4666",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555),\n",
    "                          (9876888854637815463789)\n",
    "])\n",
    "def test_infinite_capacity(random_no_set):\n",
    "    '''\n",
    "    Remove all capacity constraints in the model \n",
    "    by setting all capacity to M a large number\n",
    "    \n",
    "    Expected result:\n",
    "    -------\n",
    "    No queuing. The following KPIs = 0.0\n",
    "    \n",
    "    01a_triage_wait\n",
    "    02a_registration_wait\n",
    "    03a_examination_wait\n",
    "    04a_treatment_wait(non_trauma)\n",
    "    06a_trauma_wait'\n",
    "    07a_treatment_wait(trauma)\n",
    "    '''\n",
    "    \n",
    "    M = 100_000_000\n",
    "    \n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(n_triage=M, n_reg=M, n_exam=M, n_trauma=M, \n",
    "                        n_cubicles_1=M, n_cubicles_2=M)\n",
    "\n",
    "    # run the model in single run model\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "    \n",
    "    \n",
    "    assert (run_results['01a_triage_wait'].iloc[0] == 0.0\n",
    "            and run_results['02a_registration_wait'].iloc[0] == 0.0\n",
    "            and run_results['03a_examination_wait'].iloc[0] == 0.0\n",
    "            and run_results['04a_treatment_wait(non_trauma)'].iloc[0] == 0.0\n",
    "            and run_results['06a_trauma_wait'].iloc[0] == 0.0\n",
    "            and run_results['07a_treatment_wait(trauma)'].iloc[0] == 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "145915f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: we are ignoring mean of empty array warnings from numpy using filterwarnings\n",
    "### We will handle this in a future release of treat_sim.\n",
    "\n",
    "@pytest.mark.filterwarnings(\"ignore\")\n",
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555), \n",
    "])\n",
    "def test_no_treatment_for_nontrauma(random_no_set):\n",
    "    '''\n",
    "    Force all non-trauma patients to be discharged without treatment\n",
    "    \n",
    "    i.e. non_trauma_treat_p = 0.0\n",
    "    \n",
    "    Expected result:\n",
    "    -------\n",
    "    No non-trauma patients queue or use treatment cubicles\n",
    "    The following variable is NaN\n",
    "\n",
    "    04a_treatment_wait(non_trauma)\n",
    "    \n",
    "    and the utilisation of the non-trauma cubicles is 0\n",
    "    \n",
    "    04b_treatment_util(non_trauma)\n",
    "\n",
    "    '''\n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(non_trauma_treat_p=0.0)\n",
    "\n",
    "    # run the model in single run model\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "        \n",
    "    # run results\n",
    "    assert (pd.isna(run_results['04a_treatment_wait(non_trauma)'].iloc[0]) \n",
    "            and run_results['04b_treatment_util(non_trauma)'].iloc[0] == 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ef3c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: we are ignoring mean of empty array warnings from numpy using filterwarnings\n",
    "### We will handle this in a future release of treat_sim.\n",
    "\n",
    "@pytest.mark.filterwarnings(\"ignore\")\n",
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555), \n",
    "])\n",
    "def test_all_nontrauma_no_treatment(random_no_set):\n",
    "    '''\n",
    "    Force all patients to use the non-trauma pathway\n",
    "    \n",
    "    i.e. Set prob_trauma = 0.0 and non_trauma_treat_p = 0.0\n",
    "    \n",
    "    Expected result:\n",
    "    -------\n",
    "    No patients use the trauma pathway this means that a number of KPIs\n",
    "    if NaN (Not a Number) as no patient use the activities.\n",
    "    \n",
    "    '06a_trauma_wait'\n",
    "    '07a_treatment_wait(trauma)'\n",
    "    '08_total_time(trauma)'\n",
    "    \n",
    "    Non-trauma pathway KPIs are valid numbers. We test\n",
    "    '02a_registration_wait'\n",
    "    '05_total_time(non-trauma)'\n",
    "    \n",
    "    No non-trauma patients queue or use treatment cubicles\n",
    "    The following variable is NaN\n",
    "\n",
    "    04a_treatment_wait(non_trauma)\n",
    "    \n",
    "    and the utilisation of the non-trauma cubicles is 0\n",
    "    \n",
    "    04b_treatment_util(non_trauma)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(prob_trauma=0.0,\n",
    "                        non_trauma_treat_p=0.0)\n",
    "\n",
    "    # run the model in single run model\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "        \n",
    "    # run results\n",
    "    assert (pd.isna(run_results['06a_trauma_wait'].iloc[0]) \n",
    "            and pd.isna(run_results['07a_treatment_wait(trauma)'].iloc[0]) \n",
    "            and pd.isna(run_results['08_total_time(trauma)'].iloc[0]) \n",
    "            and not pd.isna(run_results['02a_registration_wait'].iloc[0])\n",
    "            and not pd.isna(run_results['05_total_time(non-trauma)'].iloc[0])\n",
    "            and pd.isna(run_results['04a_treatment_wait(non_trauma)'].iloc[0]) \n",
    "            and run_results['04b_treatment_util(non_trauma)'].iloc[0] == 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32929de0",
   "metadata": {},
   "source": [
    "### 3.3 Deterministic activities\n",
    "\n",
    "We have simplifed the model to a deterministic run by replacing all activity distributions with a fixed static value.\n",
    "\n",
    "> To do: This will involve modifying the Scenario class distributions. Do we allow arrivals to remain stochastic (rate and patient type?). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50919975",
   "metadata": {},
   "source": [
    "#### Functions used to overwrite `Scenario` in deterministic tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26eaa5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_sampling_to_fixed(self):\n",
    "    '''\n",
    "    Create the distributions used by the model and initialise \n",
    "    the random seeds of each.  This modified function\n",
    "    makes use of a fixed distribution where the fixed value\n",
    "    is the mean of the original sampling distribution.\n",
    "    \n",
    "    We ignore arrivals as this is handled by init_nspp()\n",
    "    \n",
    "    '''       \n",
    "    # create distributions - all are fixed apart from arrivals\n",
    "\n",
    "    # Triage duration\n",
    "    self.triage_dist = FixedDistribution(self.triage_mean)\n",
    "\n",
    "    # Registration duration (non-trauma only)\n",
    "    self.reg_dist = FixedDistribution(self.reg_mean)\n",
    "\n",
    "    # Evaluation (non-trauma only)\n",
    "    self.exam_dist = FixedDistribution(self.exam_mean)\n",
    "\n",
    "    # Trauma/stablisation duration (trauma only)\n",
    "    self.trauma_dist = FixedDistribution(self.trauma_mean)\n",
    "\n",
    "    # Non-trauma treatment\n",
    "    self.nt_treat_dist = FixedDistribution(self.non_trauma_treat_mean)\n",
    "\n",
    "    # treatment of trauma patients\n",
    "    self.treat_dist = FixedDistribution(self.trauma_treat_mean)\n",
    "\n",
    "    # probability of non-trauma patient requiring treatment\n",
    "    self.nt_p_treat_dist = FixedDistribution(self.non_trauma_treat_p)\n",
    "\n",
    "    # probability of non-trauma versus trauma patient\n",
    "    self.p_trauma_dist = FixedDistribution(self.prob_trauma)\n",
    "\n",
    "    # init sampling for non-stationary poisson process\n",
    "    # we leave this as stochastic.\n",
    "    self.init_nspp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8641580",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.filterwarnings(\"ignore\")\n",
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555), \n",
    "])\n",
    "def test_deterministic_nontrauma_pathway(random_no_set):\n",
    "    '''\n",
    "    Test a single_run of the model when the non_trauma\n",
    "    pathway is set to determinstic values with no capacity \n",
    "    constraints.\n",
    "    \n",
    "    Arrivals are left as stochastic, this should not affect\n",
    "    result.\n",
    "\n",
    "    Expected result: \n",
    "    ---------------\n",
    "        total time in system = 37.3 allowing for floating point error.\n",
    "    '''\n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    M = 1000_000_000\n",
    "\n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(n_triage=M, n_reg=M, n_exam=M, n_trauma=M, \n",
    "                        n_cubicles_1=M, n_cubicles_2=M, non_trauma_treat_p=1.0, prob_trauma=0.0)\n",
    "\n",
    "    # calculate the expected time in system = sum of deterministic activity times.\n",
    "    expected_total_time = scenario.triage_mean \\\n",
    "        + scenario.reg_mean + scenario.exam_mean + scenario.non_trauma_treat_mean\n",
    "\n",
    "    # overwrite the function\n",
    "    scenario.init_sampling = types.MethodType(init_sampling_to_fixed, scenario)\n",
    "    \n",
    "    # run the determinstic pathway (random numbers should make no difference)\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "\n",
    "    # test\n",
    "    assert pytest.approx(run_results['05_total_time(non-trauma)'].iloc[0]) == expected_total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25f591cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.filterwarnings(\"ignore\")\n",
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555), \n",
    "])\n",
    "def test_deterministic_trauma_pathway(random_no_set):\n",
    "    '''\n",
    "    Test a single_run of the model when the trauma\n",
    "    pathway is set to determinstic values with no capacity \n",
    "    constraints.\n",
    "    \n",
    "    Arrivals are left as stochastic, this should not affect\n",
    "    result.\n",
    "\n",
    "    Expected result: \n",
    "    ---------------\n",
    "        total time in system = sum(triage+stablisation+treatment) \n",
    "        allowing for floating point error.\n",
    "    '''\n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    M = 1000_000_000\n",
    "\n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(n_triage=M, n_reg=M, n_exam=M, n_trauma=M, \n",
    "                        n_cubicles_1=M, n_cubicles_2=M, prob_trauma=1.0)\n",
    "    \n",
    "    # calculate the expected time in system = sum of deterministic activity times.\n",
    "    expected_total_time = scenario.triage_mean \\\n",
    "        + scenario.trauma_mean + scenario.trauma_treat_mean\n",
    "    \n",
    "    # overwrite the function\n",
    "    scenario.init_sampling = types.MethodType(init_sampling_to_fixed, scenario)\n",
    "    \n",
    "    # run the determinstic pathway (random numbers should make no difference)\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "\n",
    "    # test\n",
    "    assert pytest.approx(run_results['08_total_time(trauma)'].iloc[0]) == expected_total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a3726d",
   "metadata": {},
   "source": [
    "## 4. Run all automated tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a30fb694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 51 items\n",
      "\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_single_run_results_length_and_type \u001b[32mPASSED\u001b[0m\u001b[32m        [  1%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_multiple_replications_results_length_and_type[1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_multiple_replications_results_length_and_type[2] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_multiple_replications_results_length_and_type[10] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_multiple_replications_results_length_and_type[23] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_random_number_set[0] \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 11%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_random_number_set[1] \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 13%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_random_number_set[2] \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 15%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_random_number_set[101] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 17%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_random_number_set[42] \u001b[32mPASSED\u001b[0m\u001b[32m                     [ 19%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_run_length_control[10.0] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 21%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_run_length_control[1000.0] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 23%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_run_length_control[25.0] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 25%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_run_length_control[500.0] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 27%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_run_length_control[143.0] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 29%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_all_trauma[42] \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 31%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_all_trauma[1] \u001b[32mPASSED\u001b[0m\u001b[32m                             [ 33%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_all_trauma[754] \u001b[32mPASSED\u001b[0m\u001b[32m                           [ 35%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_all_trauma[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 37%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_all_trauma[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 39%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_all_nontrauma[42] \u001b[32mPASSED\u001b[0m\u001b[32m                         [ 41%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_all_nontrauma[1] \u001b[32mPASSED\u001b[0m\u001b[32m                          [ 43%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_all_nontrauma[754] \u001b[32mPASSED\u001b[0m\u001b[32m                        [ 45%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_all_nontrauma[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 47%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_all_nontrauma[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 49%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_infinite_capacity[42] \u001b[32mPASSED\u001b[0m\u001b[32m                     [ 50%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_infinite_capacity[1] \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 52%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_infinite_capacity[754] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 54%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_infinite_capacity[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 56%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_infinite_capacity[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 58%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_infinite_capacity[9876888854637815463789] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_no_treatment_for_nontrauma[42] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 62%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_no_treatment_for_nontrauma[1] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 64%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_no_treatment_for_nontrauma[754] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 66%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_no_treatment_for_nontrauma[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 68%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_no_treatment_for_nontrauma[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_all_nontrauma_no_treatment[42] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 72%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_all_nontrauma_no_treatment[1] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 74%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_all_nontrauma_no_treatment[754] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 76%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_all_nontrauma_no_treatment[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 78%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_all_nontrauma_no_treatment[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_deterministic_nontrauma_pathway[42] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 82%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_deterministic_nontrauma_pathway[1] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 84%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_deterministic_nontrauma_pathway[754] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 86%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_deterministic_nontrauma_pathway[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_deterministic_nontrauma_pathway[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_deterministic_trauma_pathway[42] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 92%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_deterministic_trauma_pathway[1] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 94%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_deterministic_trauma_pathway[754] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 96%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_deterministic_trauma_pathway[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 98%]\u001b[0m\n",
      "t_1406c931e1644556bb6da91cdf501505.py::test_deterministic_trauma_pathway[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m51 passed\u001b[0m\u001b[32m in 7.87s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipytest.run(\"-vv\", \"--no-header\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
