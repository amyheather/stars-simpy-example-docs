{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4efb952e",
   "metadata": {},
   "source": [
    "# Model testing\n",
    "\n",
    "This notebook provides a set of tests to run against `treat_sim`.  These tests are either pass or fail and no interpretation is needed. A summary of test results is provided at the end of the notebook.\n",
    "\n",
    "> This notebook is a work in progress and more tests will be added in due course as we refine and/or expand `treat_sim` functionality.\n",
    "\n",
    "We have broken the testing of `treat_sim` into the following sections\n",
    "\n",
    "* **Functionality tests:**.  These provide tests of the overall setup and features of using the model including the ability to do repeatable single and multiple replications.\n",
    "* **Extreme value tests:** The model is configured with extreme values for its parameters. For example, limiting arrivals, blocking routes, infinite capacity.  This helps test that the logic of the model is implemented correctly.\n",
    "* **Deterministic run tests:** Test if the total time in the pathway output behaves as expected if activites are converted to a deterministic values and capacity is removed. \n",
    "\n",
    "These tests are only valid for a specific version of `treat_sim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3782e443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## these tests are applied to treat_sim version =\n",
    "import treat_sim\n",
    "treat_sim.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dac3b02",
   "metadata": {},
   "source": [
    "## 1. Model Code Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "123f010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from treat_sim.model import (\n",
    "    Scenario, \n",
    "    TreatmentCentreModel,\n",
    "    single_run, \n",
    "    multiple_replications,\n",
    "    SimulationSummary,\n",
    "    DEFAULT_N_TRIAGE,\n",
    "    DEFAULT_N_REG,\n",
    "    DEFAULT_REG_MEAN,\n",
    "    DEFAULT_TRAUMA_TREAT_MEAN,\n",
    "    DEFAULT_PROB_TRAUMA\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2649e8",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0da2d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import pytest\n",
    "import ipytest\n",
    "\n",
    "# types library is used to overwrite methods from treat_sim\n",
    "import types\n",
    "\n",
    "# sim_tools fixed dist is used for deterministic runs\n",
    "from sim_tools.distributions import FixedDistribution\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d9602",
   "metadata": {},
   "source": [
    "## 3. Tests\n",
    "\n",
    "### 3.1 Functionality tests\n",
    "\n",
    "Here we test that various modes of running the model work correctly.  These include\n",
    "\n",
    "* single run mode\n",
    "* multiple replications mode\n",
    "* repeatable results using random number sets.\n",
    "* results collection period\n",
    "* TODO: the number of patient arrivals\n",
    "* TODO: the number of patient arrivals given an alternative time dependent profile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d785f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_run_results_length_and_type():\n",
    "    '''\n",
    "    Test a single_run of the model.\n",
    "    \n",
    "    The single_run function should return a pandas.DataFrame\n",
    "    containing 16 columns and a single row.\n",
    "    \n",
    "     0   00_arrivals                    \n",
    "     1   01a_triage_wait                 \n",
    "     2   01b_triage_util               \n",
    "     3   02a_registration_wait         \n",
    "     4   02b_registration_util        \n",
    "     5   03a_examination_wait          \n",
    "     6   03b_examination_util          \n",
    "     7   04a_treatment_wait(non_trauma)  \n",
    "     8   04b_treatment_util(non_trauma)  \n",
    "     9   05_total_time(non-trauma)       \n",
    "     10  06a_trauma_wait               \n",
    "     11  06b_trauma_util                 \n",
    "     12  07a_treatment_wait(trauma)      \n",
    "     13  07b_treatment_util(trauma)      \n",
    "     14  08_total_time(trauma)           \n",
    "     15  09_throughput                   \n",
    "\n",
    "    Expected result: \n",
    "    ---------------\n",
    "        len(run_results) == 16 and isinstance(run_results, pd.Dataframe)\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    bool: does the model pass the test.\n",
    "    '''\n",
    "    EXPECTED_LENGTH = 16\n",
    "\n",
    "    # a default experiment\n",
    "    default_experiment_params = Scenario()\n",
    "\n",
    "    # run the model in single run model\n",
    "    run_results = single_run(default_experiment_params, random_no_set=41)\n",
    "\n",
    "    # test\n",
    "    assert len(run_results.T) == EXPECTED_LENGTH and isinstance(run_results, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece2adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('n_reps', [\n",
    "                          (1),\n",
    "                          (2),\n",
    "                          (10),\n",
    "                          (23)\n",
    "])\n",
    "def test_multiple_replications_results_length_and_type(n_reps):\n",
    "    '''\n",
    "    Test running the model in multiple replications mode\n",
    "    \n",
    "    The multiple function should return a pandas.DataFrame\n",
    "    containing 16 columns and n_reps rows. Its shape is (n_reps, 16)\n",
    "    \n",
    "     0   00_arrivals                    \n",
    "     1   01a_triage_wait                 \n",
    "     2   01b_triage_util               \n",
    "     3   02a_registration_wait         \n",
    "     4   02b_registration_util        \n",
    "     5   03a_examination_wait          \n",
    "     6   03b_examination_util          \n",
    "     7   04a_treatment_wait(non_trauma)  \n",
    "     8   04b_treatment_util(non_trauma)  \n",
    "     9   05_total_time(non-trauma)       \n",
    "     10  06a_trauma_wait               \n",
    "     11  06b_trauma_util                 \n",
    "     12  07a_treatment_wait(trauma)      \n",
    "     13  07b_treatment_util(trauma)      \n",
    "     14  08_total_time(trauma)           \n",
    "     15  09_throughput                   \n",
    "\n",
    "    Expected result: \n",
    "    ---------------\n",
    "        rep_results.shape == (n_reps, 16) and isinstance(rep_results, pd.DataFrame)\n",
    "    '''\n",
    "    EXPECTED_N_COLUMNS = 16\n",
    "    EXPECTED_SHAPE = (n_reps, EXPECTED_N_COLUMNS)\n",
    "\n",
    "    # a default experiment\n",
    "    default_experiment_params = Scenario()\n",
    "\n",
    "    # run the model in multiple replications mode\n",
    "    rep_results = multiple_replications(default_experiment_params, n_reps=n_reps)\n",
    "\n",
    "    # test\n",
    "    assert rep_results.shape == EXPECTED_SHAPE and isinstance(rep_results, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a463ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('random_number_set', [\n",
    "                          (0),\n",
    "                          (1),\n",
    "                          (2),\n",
    "                          (101),\n",
    "                          (42),\n",
    "])\n",
    "def test_random_number_set(random_number_set):\n",
    "    '''\n",
    "    Test the model produces repeatable results\n",
    "    given the same set set of random seeds.\n",
    "    \n",
    "    Expected result: \n",
    "    ---------------\n",
    "        difference between data frames is 0.0\n",
    "    '''\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(2):\n",
    "        \n",
    "        exp = Scenario()\n",
    "\n",
    "        # run the model in single run model\n",
    "        run_results = single_run(exp, random_no_set=random_number_set)\n",
    "    \n",
    "        results.append(run_results)\n",
    "        \n",
    "    # test\n",
    "    assert (results[0] - results[1]).sum().sum() == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5329f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('rc_period', [\n",
    "                          (10.0),\n",
    "                          (1_000.0),\n",
    "                          (25.0),\n",
    "                          (500.0),\n",
    "                          (143.0),\n",
    "])\n",
    "def test_run_length_control(rc_period):\n",
    "    '''\n",
    "    Test that the simulation model can be set up \n",
    "    to run different results collection period.\n",
    "    \n",
    "    '''\n",
    "    scenario = Scenario()\n",
    "    \n",
    "    # set random number set - this controls sampling for the run.\n",
    "    scenario.set_random_no_set(42)\n",
    "\n",
    "    # create an instance of the model\n",
    "    model = TreatmentCentreModel(scenario)\n",
    "\n",
    "    # run the model\n",
    "    model.run(results_collection_period=rc_period)\n",
    "        \n",
    "    # run results\n",
    "    assert model.env.now == rc_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f4d32fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from treat_sim.model import Exponential, Uniform\n",
    "\n",
    "# created for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9152e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('arrival_profile', [\n",
    "                          ('data/ed_arrivals.csv'), \n",
    "                          ('data/ed_arrivals_test_1.csv'), \n",
    "    \n",
    "])\n",
    "def test_arrival_numbers(arrival_profile):\n",
    "    '''\n",
    "    Test that the number of arrivals in a day is correct\n",
    "    on average using a different arrival profiles. \n",
    "    This includes the default used in the application.\n",
    "    \n",
    "    The multiple_replications function is used to generate\n",
    "    the mean number of arrivals over 100 replications.\n",
    "    \n",
    "    We allow for a 1% sampling deviation.\n",
    "    \n",
    "    00_arrivals                               \n",
    "\n",
    "    Expected result: \n",
    "    ---------------\n",
    "        mean arrivals = sum(arrival_rate from input file)\n",
    "\n",
    "    '''\n",
    "    # this function replaces Scenario.init_nspp()\n",
    "    # We use this approach because in treat_sim v2.0.0\n",
    "    # the path to the profile is hard coded and cannot be \n",
    "    # set directly when the Scenario is created.\n",
    "    def init_nspp_for_testing(self):\n",
    "\n",
    "        # read arrival profile\n",
    "        self.arrivals = pd.read_csv(arrival_profile)\n",
    "        self.arrivals['mean_iat'] = 60 / self.arrivals['arrival_rate']\n",
    "        print(sum(self.arrivals['arrival_rate']))\n",
    "\n",
    "        # maximum arrival rate (smallest time between arrivals)\n",
    "        self.lambda_max = self.arrivals['arrival_rate'].max()\n",
    "\n",
    "        # thinning exponential\n",
    "        self.arrival_dist = Exponential(60.0 / self.lambda_max,\n",
    "                                        random_seed=self.seeds[8])\n",
    "\n",
    "        # thinning uniform rng\n",
    "        self.thinning_rng = Uniform(low=0.0, high=1.0, \n",
    "                                    random_seed=self.seeds[9])\n",
    "    \n",
    "    arrival_data = pd.read_csv(arrival_profile)\n",
    "    expected_patients = arrival_data['arrival_rate'].sum()\n",
    "    \n",
    "    # a default experiment\n",
    "    scenario = Scenario()\n",
    "    # overwrite the nspp init function in the scenario class\n",
    "    scenario.init_nspp = types.MethodType(init_nspp_for_testing, scenario)\n",
    "\n",
    "    # run the model in multiple_reps mode\n",
    "    results = multiple_replications(scenario, n_reps=100)\n",
    "    # summary results...\n",
    "    mean_results = results.mean().round(2)\n",
    "    \n",
    "    # test\n",
    "    assert pytest.approx(mean_results['00_arrivals'], rel=0.01) == expected_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "506555bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('n_triage, n_reg, reg_mean, trauma_treat_mean, prob_trauma', [\n",
    "                          (DEFAULT_N_TRIAGE, DEFAULT_N_REG, DEFAULT_REG_MEAN, DEFAULT_TRAUMA_TREAT_MEAN, DEFAULT_PROB_TRAUMA),\n",
    "                          (5, DEFAULT_N_REG, DEFAULT_REG_MEAN, DEFAULT_TRAUMA_TREAT_MEAN, DEFAULT_PROB_TRAUMA),\n",
    "                          (DEFAULT_N_TRIAGE, 5, DEFAULT_REG_MEAN, DEFAULT_TRAUMA_TREAT_MEAN, 0.5),\n",
    "                          (DEFAULT_N_TRIAGE, DEFAULT_N_REG, 15.0, DEFAULT_TRAUMA_TREAT_MEAN, 0.25),\n",
    "                          (42, DEFAULT_N_REG, DEFAULT_REG_MEAN, 65.2, DEFAULT_PROB_TRAUMA),\n",
    "])\n",
    "def test_parameters_stay_constant(n_triage, n_reg, reg_mean, trauma_treat_mean, \n",
    "                                  prob_trauma):\n",
    "    '''\n",
    "    Test that the Scenario parameters are not\n",
    "    modified during the run.\n",
    "    \n",
    "    Recommended by Banks et al in verification section.\n",
    "    \n",
    "    We modify the test slightly by running multiple\n",
    "    tests with a small selection of parameters.\n",
    "    \n",
    "    Expected result:\n",
    "    ---------------\n",
    "    No change to the experimental parameters during a run.\n",
    "    '''\n",
    "    \n",
    "    def scenario_params_are_equal(to_test, before_run):\n",
    "               \n",
    "        return (to_test.n_triage == before_run.n_triage\n",
    "        and to_test.n_reg == before_run.n_reg\n",
    "        and to_test.n_exam == before_run.n_exam\n",
    "        and to_test.n_trauma == before_run.n_trauma\n",
    "        and to_test.n_cubicles_1 == before_run.n_cubicles_1\n",
    "        and to_test.n_cubicles_2 == before_run.n_cubicles_2\n",
    "        and to_test.triage_mean == before_run.triage_mean\n",
    "        and to_test.reg_mean == before_run.reg_mean\n",
    "        and to_test.reg_var == before_run.reg_var\n",
    "        and to_test.exam_mean == before_run.exam_mean\n",
    "        and to_test.exam_var == before_run.exam_var\n",
    "        and to_test.exam_min == before_run.exam_min\n",
    "        and to_test.trauma_mean == before_run.trauma_mean\n",
    "        and to_test.trauma_treat_mean == before_run.trauma_treat_mean\n",
    "        and to_test.trauma_treat_var == before_run.trauma_treat_var\n",
    "        and to_test.non_trauma_treat_mean == before_run.non_trauma_treat_mean\n",
    "        and to_test.non_trauma_treat_var == before_run.non_trauma_treat_var\n",
    "        and to_test.non_trauma_treat_p == before_run.non_trauma_treat_p\n",
    "        and to_test.prob_trauma == before_run.prob_trauma)\n",
    "\n",
    "    \n",
    "    # this is the scenario we run\n",
    "    scenario_to_run_with_model = Scenario(n_triage=n_triage, n_reg=n_reg, \n",
    "                                          reg_mean=reg_mean, trauma_treat_mean=trauma_treat_mean, \n",
    "                                          prob_trauma=prob_trauma)\n",
    "    \n",
    "    # this is a copy of the scenario that we use to test that there is no modification to parmas\n",
    "    scenario_to_compare = Scenario(n_triage=n_triage, n_reg=n_reg, \n",
    "                                   reg_mean=reg_mean, trauma_treat_mean=trauma_treat_mean, \n",
    "                                   prob_trauma=prob_trauma)\n",
    "    \n",
    "    # run model - we are not interested in restuls.\n",
    "    _ = single_run(scenario_to_run_with_model, random_no_set=101)\n",
    "    \n",
    "    # compare\n",
    "    assert scenario_params_are_equal(scenario_to_run_with_model, scenario_to_compare)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2948de",
   "metadata": {},
   "source": [
    "### 3.2. Extreme value tests\n",
    "\n",
    "Here we manipulate the input parameters of the model to test that it behaves as expected. We run the following tests\n",
    "\n",
    "* All arrivals are trauma\n",
    "* All arrivals are non-trauma\n",
    "* Infinite capacity for activities\n",
    "* All non-trauma patients require treatment\n",
    "* All non-trauma patients do not require treatment\n",
    "* Block trauma arrivals at stabilisation\n",
    "* Block non-trauma arrivals at examination\n",
    "* Block all arrivals at triage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06319053",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: we are ignoring mean of empty array warnings from numpy using filterwarnings\n",
    "### We will handle this in a future release of treat_sim.\n",
    "\n",
    "@pytest.mark.filterwarnings(\"ignore\")\n",
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555), \n",
    "])\n",
    "def test_all_trauma(random_no_set):\n",
    "    '''\n",
    "    Force all patients to use trauma pathway\n",
    "    \n",
    "    i.e. Set prob_trauma = 1.0\n",
    "    \n",
    "    Expected result:\n",
    "    -------\n",
    "    No patients use the non-trauma pathway this means that a number of KPIs\n",
    "    are NaN (not a number). These include:\n",
    "    '02a_registration_wait'\n",
    "    '05_total_time(non-trauma)'\n",
    "    \n",
    "    Trauma pathway KPIs are valid numbers. We test total time in \n",
    "    system: '08_total_time(trauma)'\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(prob_trauma=1.0)\n",
    "\n",
    "    # run the model in single run model\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "        \n",
    "    # run results\n",
    "    assert (pd.isna(run_results['05_total_time(non-trauma)'].iloc[0]) \n",
    "            and pd.isna(run_results['02a_registration_wait'].iloc[0]) \n",
    "            and not pd.isna(run_results['08_total_time(trauma)'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd4bbc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: we are ignoring mean of empty array warnings from numpy using filterwarnings\n",
    "### We will handle this in a future release of treat_sim.\n",
    "\n",
    "@pytest.mark.filterwarnings(\"ignore\")\n",
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555), \n",
    "])\n",
    "def test_all_nontrauma(random_no_set):\n",
    "    '''\n",
    "    Force all patients to use the non-trauma pathway\n",
    "    \n",
    "    i.e. Set prob_trauma = 0.0\n",
    "    \n",
    "    Expected result:\n",
    "    -------\n",
    "    No patients use the trauma pathway this means that a number of KPIs\n",
    "    if NaN (Not a Number) as no patient use the activities.\n",
    "    \n",
    "    '06a_trauma_wait'\n",
    "    '07a_treatment_wait(trauma)'\n",
    "    '08_total_time(trauma)'\n",
    "    \n",
    "    Non-trauma pathway KPIs are valid numbers. We test\n",
    "    '02a_registration_wait'\n",
    "    '05_total_time(non-trauma)'\n",
    "    '''\n",
    "    \n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(prob_trauma=0.0)\n",
    "\n",
    "    # run the model in single run model\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "        \n",
    "    # run results\n",
    "    assert (pd.isna(run_results['06a_trauma_wait'].iloc[0]) \n",
    "            and pd.isna(run_results['07a_treatment_wait(trauma)'].iloc[0]) \n",
    "            and pd.isna(run_results['08_total_time(trauma)'].iloc[0]) \n",
    "            and not pd.isna(run_results['02a_registration_wait'].iloc[0])\n",
    "            and not pd.isna(run_results['05_total_time(non-trauma)'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1b698e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555),\n",
    "                          (9876888854637815463789)\n",
    "])\n",
    "def test_infinite_capacity(random_no_set):\n",
    "    '''\n",
    "    Remove all capacity constraints in the model \n",
    "    by setting all capacity to M a large number\n",
    "    \n",
    "    Expected result:\n",
    "    -------\n",
    "    No queuing. The following KPIs = 0.0\n",
    "    \n",
    "    01a_triage_wait\n",
    "    02a_registration_wait\n",
    "    03a_examination_wait\n",
    "    04a_treatment_wait(non_trauma)\n",
    "    06a_trauma_wait'\n",
    "    07a_treatment_wait(trauma)\n",
    "    '''\n",
    "    \n",
    "    M = 100_000_000\n",
    "    \n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(n_triage=M, n_reg=M, n_exam=M, n_trauma=M, \n",
    "                        n_cubicles_1=M, n_cubicles_2=M)\n",
    "\n",
    "    # run the model in single run model\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "    \n",
    "    \n",
    "    assert (run_results['01a_triage_wait'].iloc[0] == 0.0\n",
    "            and run_results['02a_registration_wait'].iloc[0] == 0.0\n",
    "            and run_results['03a_examination_wait'].iloc[0] == 0.0\n",
    "            and run_results['04a_treatment_wait(non_trauma)'].iloc[0] == 0.0\n",
    "            and run_results['06a_trauma_wait'].iloc[0] == 0.0\n",
    "            and run_results['07a_treatment_wait(trauma)'].iloc[0] == 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0c365cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: we are ignoring mean of empty array warnings from numpy using filterwarnings\n",
    "### We will handle this in a future release of treat_sim.\n",
    "\n",
    "@pytest.mark.filterwarnings(\"ignore\")\n",
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555), \n",
    "])\n",
    "def test_no_treatment_for_nontrauma(random_no_set):\n",
    "    '''\n",
    "    Force all non-trauma patients to be discharged without treatment\n",
    "    \n",
    "    i.e. non_trauma_treat_p = 0.0\n",
    "    \n",
    "    Expected result:\n",
    "    -------\n",
    "    No non-trauma patients queue or use treatment cubicles\n",
    "    The following variable is NaN\n",
    "\n",
    "    04a_treatment_wait(non_trauma)\n",
    "    \n",
    "    and the utilisation of the non-trauma cubicles is 0\n",
    "    \n",
    "    04b_treatment_util(non_trauma)\n",
    "\n",
    "    '''\n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(non_trauma_treat_p=0.0)\n",
    "\n",
    "    # run the model in single run model\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "        \n",
    "    # run results\n",
    "    assert (pd.isna(run_results['04a_treatment_wait(non_trauma)'].iloc[0]) \n",
    "            and run_results['04b_treatment_util(non_trauma)'].iloc[0] == 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cd89e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: we are ignoring mean of empty array warnings from numpy using filterwarnings\n",
    "### We will handle this in a future release of treat_sim.\n",
    "\n",
    "@pytest.mark.filterwarnings(\"ignore\")\n",
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555), \n",
    "])\n",
    "def test_all_nontrauma_no_treatment(random_no_set):\n",
    "    '''\n",
    "    Force all patients to use the non-trauma pathway\n",
    "    \n",
    "    i.e. Set prob_trauma = 0.0 and non_trauma_treat_p = 0.0\n",
    "    \n",
    "    Expected result:\n",
    "    -------\n",
    "    No patients use the trauma pathway this means that a number of KPIs\n",
    "    if NaN (Not a Number) as no patient use the activities.\n",
    "    \n",
    "    '06a_trauma_wait'\n",
    "    '07a_treatment_wait(trauma)'\n",
    "    '08_total_time(trauma)'\n",
    "    \n",
    "    Non-trauma pathway KPIs are valid numbers. We test\n",
    "    '02a_registration_wait'\n",
    "    '05_total_time(non-trauma)'\n",
    "    \n",
    "    No non-trauma patients queue or use treatment cubicles\n",
    "    The following variable is NaN\n",
    "\n",
    "    04a_treatment_wait(non_trauma)\n",
    "    \n",
    "    and the utilisation of the non-trauma cubicles is 0\n",
    "    \n",
    "    04b_treatment_util(non_trauma)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(prob_trauma=0.0,\n",
    "                        non_trauma_treat_p=0.0)\n",
    "\n",
    "    # run the model in single run model\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "        \n",
    "    # run results\n",
    "    assert (pd.isna(run_results['06a_trauma_wait'].iloc[0]) \n",
    "            and pd.isna(run_results['07a_treatment_wait(trauma)'].iloc[0]) \n",
    "            and pd.isna(run_results['08_total_time(trauma)'].iloc[0]) \n",
    "            and not pd.isna(run_results['02a_registration_wait'].iloc[0])\n",
    "            and not pd.isna(run_results['05_total_time(non-trauma)'].iloc[0])\n",
    "            and pd.isna(run_results['04a_treatment_wait(non_trauma)'].iloc[0]) \n",
    "            and run_results['04b_treatment_util(non_trauma)'].iloc[0] == 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88feabb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: we are ignoring mean of empty array warnings from numpy using filterwarnings\n",
    "### We will handle this in a future release of treat_sim.\n",
    "\n",
    "@pytest.mark.filterwarnings(\"ignore\")\n",
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555), \n",
    "])\n",
    "def test_block_trauma_at_stabilisation(random_no_set):\n",
    "    '''\n",
    "    Block all trauma patients at stablisation\n",
    "    This is achieved by setting mean trauma time to\n",
    "    M a very large number.\n",
    "    \n",
    "    Expected result:\n",
    "    -------\n",
    "    Trauma pathway total_time in system = NaN    \n",
    "    Non_trama pathway operates as expected. Not NaN\n",
    "    '''\n",
    "    M = 100_000_000\n",
    "    \n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(trauma_mean=M)\n",
    "\n",
    "    # run the model in single run model\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "        \n",
    "    # run results\n",
    "    assert (pd.isna(run_results['08_total_time(trauma)'].iloc[0]) \n",
    "            and not pd.isna(run_results['05_total_time(non-trauma)'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "122645b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: we are ignoring mean of empty array warnings from numpy using filterwarnings\n",
    "### We will handle this in a future release of treat_sim.\n",
    "\n",
    "@pytest.mark.filterwarnings(\"ignore\")\n",
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555), \n",
    "])\n",
    "def test_block_nontrauma_at_examination(random_no_set):\n",
    "    '''\n",
    "    Block all non trauma patients at examination\n",
    "    This is achieved by setting mean examination time to\n",
    "    M a very large number.\n",
    "\n",
    "    Expected result:\n",
    "    -------\n",
    "    Trauma pathway total_time in system is normal i.e. not a NaN    \n",
    "    Non_trama pathway total pathway time is NaN and waiting time for\n",
    "    treatment is NaN\n",
    "    '''\n",
    "    M = 100_000_000\n",
    "    \n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(exam_mean=M)\n",
    "\n",
    "    # run the model in single run model\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "        \n",
    "    # run results\n",
    "    assert (not pd.isna(run_results['08_total_time(trauma)'].iloc[0]) \n",
    "            and pd.isna(run_results['04a_treatment_wait(non_trauma)'].iloc[0])\n",
    "            and pd.isna(run_results['05_total_time(non-trauma)'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a181d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: we are ignoring mean of empty array warnings from numpy using filterwarnings\n",
    "### We will handle this in a future release of treat_sim.\n",
    "\n",
    "@pytest.mark.filterwarnings(\"ignore\")\n",
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555), \n",
    "])\n",
    "def test_block_all_arrivals_at_triage(random_no_set):\n",
    "    '''\n",
    "    Block all all patient arrivals at triage\n",
    "    This is achieved by setting mean triage time to\n",
    "    M a very large number.  We will set triage capacity to 1.\n",
    "    This also means that the queue length of triage will be arrivals - 1\n",
    "\n",
    "    Expected result:\n",
    "    -------\n",
    "    Trauma pathway total_time in system is normal i.e. not a NaN    \n",
    "    Non_trama pathway total pathway time is NaN and waiting time for\n",
    "    treatment is NaN\n",
    "    \n",
    "    Notes:\n",
    "    -----\n",
    "    After a TreatmentCentreModel has been initialised by single_run\n",
    "    a variable called `triage` is available. This is the simpy.Resource\n",
    "    representing triage capacity.\n",
    "    \n",
    "    '''\n",
    "    M = 100_000_000\n",
    "    \n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(triage_mean=M, n_triage=1)\n",
    "    \n",
    "    # run the model in single run model\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "        \n",
    "    # run results\n",
    "    assert (pd.isna(run_results['08_total_time(trauma)'].iloc[0]) \n",
    "            and pd.isna(run_results['05_total_time(non-trauma)'].iloc[0])\n",
    "            and len(scenario.triage.queue) == run_results['00_arrivals'].iloc[0] - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf1b4f",
   "metadata": {},
   "source": [
    "### 3.3 Deterministic activities\n",
    "\n",
    "We have simplifed the model to a deterministic run by replacing all activity distributions with a fixed static value.\n",
    "\n",
    "> To do: This will involve modifying the Scenario class distributions. Do we allow arrivals to remain stochastic (rate and patient type?). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9305f",
   "metadata": {},
   "source": [
    "#### Functions used to overwrite `Scenario` in deterministic tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90ee1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_sampling_to_fixed(self):\n",
    "    '''\n",
    "    Create the distributions used by the model and initialise \n",
    "    the random seeds of each.  This modified function\n",
    "    makes use of a fixed distribution where the fixed value\n",
    "    is the mean of the original sampling distribution.\n",
    "    \n",
    "    We ignore arrivals as this is handled by init_nspp()\n",
    "    \n",
    "    '''       \n",
    "    # create distributions - all are fixed apart from arrivals\n",
    "\n",
    "    # Triage duration\n",
    "    self.triage_dist = FixedDistribution(self.triage_mean)\n",
    "\n",
    "    # Registration duration (non-trauma only)\n",
    "    self.reg_dist = FixedDistribution(self.reg_mean)\n",
    "\n",
    "    # Evaluation (non-trauma only)\n",
    "    self.exam_dist = FixedDistribution(self.exam_mean)\n",
    "\n",
    "    # Trauma/stablisation duration (trauma only)\n",
    "    self.trauma_dist = FixedDistribution(self.trauma_mean)\n",
    "\n",
    "    # Non-trauma treatment\n",
    "    self.nt_treat_dist = FixedDistribution(self.non_trauma_treat_mean)\n",
    "\n",
    "    # treatment of trauma patients\n",
    "    self.treat_dist = FixedDistribution(self.trauma_treat_mean)\n",
    "\n",
    "    # probability of non-trauma patient requiring treatment\n",
    "    self.nt_p_treat_dist = FixedDistribution(self.non_trauma_treat_p)\n",
    "\n",
    "    # probability of non-trauma versus trauma patient\n",
    "    self.p_trauma_dist = FixedDistribution(self.prob_trauma)\n",
    "\n",
    "    # init sampling for non-stationary poisson process\n",
    "    # we leave this as stochastic.\n",
    "    self.init_nspp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87c8aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.filterwarnings(\"ignore\")\n",
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555), \n",
    "])\n",
    "def test_deterministic_nontrauma_pathway(random_no_set):\n",
    "    '''\n",
    "    Test a single_run of the model when the non_trauma\n",
    "    pathway is set to determinstic values with no capacity \n",
    "    constraints.\n",
    "    \n",
    "    Arrivals are left as stochastic, this should not affect\n",
    "    result.\n",
    "\n",
    "    Expected result: \n",
    "    ---------------\n",
    "        total time in system = 37.3 allowing for floating point error.\n",
    "    '''\n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    M = 1000_000_000\n",
    "\n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(n_triage=M, n_reg=M, n_exam=M, n_trauma=M, \n",
    "                        n_cubicles_1=M, n_cubicles_2=M, non_trauma_treat_p=1.0, prob_trauma=0.0)\n",
    "\n",
    "    # calculate the expected time in system = sum of deterministic activity times.\n",
    "    expected_total_time = scenario.triage_mean \\\n",
    "        + scenario.reg_mean + scenario.exam_mean + scenario.non_trauma_treat_mean\n",
    "\n",
    "    # overwrite the function\n",
    "    scenario.init_sampling = types.MethodType(init_sampling_to_fixed, scenario)\n",
    "    \n",
    "    # run the determinstic pathway (random numbers should make no difference)\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "\n",
    "    # test\n",
    "    assert pytest.approx(run_results['05_total_time(non-trauma)'].iloc[0]) == expected_total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efc207e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.filterwarnings(\"ignore\")\n",
    "@pytest.mark.parametrize('random_no_set', [\n",
    "                          (42),\n",
    "                          (1),\n",
    "                          (754),\n",
    "                          (9876534321),\n",
    "                          (76546783986555), \n",
    "])\n",
    "def test_deterministic_trauma_pathway(random_no_set):\n",
    "    '''\n",
    "    Test a single_run of the model when the trauma\n",
    "    pathway is set to determinstic values with no capacity \n",
    "    constraints.\n",
    "    \n",
    "    Arrivals are left as stochastic, this should not affect\n",
    "    result.\n",
    "\n",
    "    Expected result: \n",
    "    ---------------\n",
    "        total time in system = sum(triage+stablisation+treatment) \n",
    "        allowing for floating point error.\n",
    "    '''\n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    M = 1000_000_000\n",
    "\n",
    "    # create a new scenario and set prob of trauma to 100%\n",
    "    scenario = Scenario(n_triage=M, n_reg=M, n_exam=M, n_trauma=M, \n",
    "                        n_cubicles_1=M, n_cubicles_2=M, prob_trauma=1.0)\n",
    "    \n",
    "    # calculate the expected time in system = sum of deterministic activity times.\n",
    "    expected_total_time = scenario.triage_mean \\\n",
    "        + scenario.trauma_mean + scenario.trauma_treat_mean\n",
    "    \n",
    "    # overwrite the function\n",
    "    scenario.init_sampling = types.MethodType(init_sampling_to_fixed, scenario)\n",
    "    \n",
    "    # run the determinstic pathway (random numbers should make no difference)\n",
    "    run_results = single_run(scenario, random_no_set=random_no_set)\n",
    "\n",
    "    # test\n",
    "    assert pytest.approx(run_results['08_total_time(trauma)'].iloc[0]) == expected_total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e5d875",
   "metadata": {},
   "source": [
    "## 4. Run all automated tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e38bb6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 73 items\n",
      "\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_single_run_results_length_and_type \u001b[32mPASSED\u001b[0m\u001b[32m        [  1%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_multiple_replications_results_length_and_type[1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_multiple_replications_results_length_and_type[2] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_multiple_replications_results_length_and_type[10] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_multiple_replications_results_length_and_type[23] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_random_number_set[0] \u001b[32mPASSED\u001b[0m\u001b[32m                      [  8%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_random_number_set[1] \u001b[32mPASSED\u001b[0m\u001b[32m                      [  9%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_random_number_set[2] \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 10%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_random_number_set[101] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 12%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_random_number_set[42] \u001b[32mPASSED\u001b[0m\u001b[32m                     [ 13%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_run_length_control[10.0] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 15%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_run_length_control[1000.0] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 16%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_run_length_control[25.0] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 17%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_run_length_control[500.0] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 19%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_run_length_control[143.0] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 20%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_arrival_numbers[data/ed_arrivals.csv] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 21%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_arrival_numbers[data/ed_arrivals_test_1.csv] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_parameters_stay_constant[1-1-5.0-30.0-0.12] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_parameters_stay_constant[5-1-5.0-30.0-0.12] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_parameters_stay_constant[1-5-5.0-30.0-0.5] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_parameters_stay_constant[1-1-15.0-30.0-0.25] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_parameters_stay_constant[42-1-5.0-65.2-0.12] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_all_trauma[42] \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 31%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_all_trauma[1] \u001b[32mPASSED\u001b[0m\u001b[32m                             [ 32%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_all_trauma[754] \u001b[32mPASSED\u001b[0m\u001b[32m                           [ 34%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_all_trauma[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 35%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_all_trauma[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 36%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_all_nontrauma[42] \u001b[32mPASSED\u001b[0m\u001b[32m                         [ 38%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_all_nontrauma[1] \u001b[32mPASSED\u001b[0m\u001b[32m                          [ 39%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_all_nontrauma[754] \u001b[32mPASSED\u001b[0m\u001b[32m                        [ 41%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_all_nontrauma[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 42%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_all_nontrauma[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 43%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_infinite_capacity[42] \u001b[32mPASSED\u001b[0m\u001b[32m                     [ 45%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_infinite_capacity[1] \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 46%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_infinite_capacity[754] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 47%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_infinite_capacity[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 49%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_infinite_capacity[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 50%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_infinite_capacity[9876888854637815463789] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_no_treatment_for_nontrauma[42] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 53%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_no_treatment_for_nontrauma[1] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 54%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_no_treatment_for_nontrauma[754] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 56%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_no_treatment_for_nontrauma[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 57%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_no_treatment_for_nontrauma[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_all_nontrauma_no_treatment[42] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 60%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_all_nontrauma_no_treatment[1] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 61%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_all_nontrauma_no_treatment[754] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 63%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_all_nontrauma_no_treatment[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 64%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_all_nontrauma_no_treatment[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_block_trauma_at_stabilisation[42] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 67%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_block_trauma_at_stabilisation[1] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 68%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_block_trauma_at_stabilisation[754] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 69%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_block_trauma_at_stabilisation[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_block_trauma_at_stabilisation[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_block_nontrauma_at_examination[42] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 73%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_block_nontrauma_at_examination[1] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 75%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_block_nontrauma_at_examination[754] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 76%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_block_nontrauma_at_examination[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_block_nontrauma_at_examination[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_block_all_arrivals_at_triage[42] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 80%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_block_all_arrivals_at_triage[1] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 82%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_block_all_arrivals_at_triage[754] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 83%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_block_all_arrivals_at_triage[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 84%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_block_all_arrivals_at_triage[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_deterministic_nontrauma_pathway[42] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 87%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_deterministic_nontrauma_pathway[1] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 89%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_deterministic_nontrauma_pathway[754] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 90%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_deterministic_nontrauma_pathway[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_deterministic_nontrauma_pathway[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_deterministic_trauma_pathway[42] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 94%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_deterministic_trauma_pathway[1] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 95%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_deterministic_trauma_pathway[754] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 97%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_deterministic_trauma_pathway[9876534321] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 98%]\u001b[0m\n",
      "t_1dcc749783ab4aad97178ac659df74f7.py::test_deterministic_trauma_pathway[76546783986555] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================= \u001b[32m\u001b[1m73 passed\u001b[0m\u001b[32m in 18.47s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipytest.run(\"-vv\", \"--no-header\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
